


import sys
import os
import numpy as np
import pandas as pd
import re
import logging


# –í–°–¢–†–ê–ò–í–ê–ï–ú SuperEnhancedTextAnalyzer –ü–†–Ø–ú–û –í –§–ê–ô–õ
class SuperEnhancedTextAnalyzer:
    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # –†–ê–°–®–ò–†–ï–ù–ù–´–ô –°–õ–û–í–ê–†–¨ –°–ò–ù–û–ù–ò–ú–û–í (200+ –ø–∞—Ä)
        self.technical_synonyms = {
            # –û–°–ù–û–í–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´
            '–æ—Ç–≤–µ—Ä—Ç–∫–∞': '–æ—Ç–≤–µ—Ä—Ç–æ—á–Ω–∞—è',
            '–æ—Ç–≤–µ—Ä—Ç–æ—á–Ω–∞—è': '–æ—Ç–≤–µ—Ä—Ç–∫–∞',
            '–±–∏—Ç–∞': '–æ—Ç–≤–µ—Ä—Ç–æ—á–Ω–∞—è',
            '–±–∏—Ç—ã': '–æ—Ç–≤–µ—Ä—Ç–∫–∏',

            # –¢–ò–ü–´ –û–¢–í–ï–†–¢–û–ö
            '–∫—Ä–µ—Å—Ç–æ–æ–±—Ä–∞–∑–Ω–∞—è': 'phillips',
            'phillips': '–∫—Ä–µ—Å—Ç–æ–æ–±—Ä–∞–∑–Ω–∞—è',
            'ph': 'phillips',
            'pz': 'pozidriv',
            'pozidriv': 'pz',
            '—à–ª–∏—Ü–µ–≤–∞—è': 'slotted',
            'slotted': '—à–ª–∏—Ü–µ–≤–∞—è',
            'sl': 'slotted',
            '–ø—Ä—è–º–∞—è': 'slotted',

            # HEX –ò TORX
            '—à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫': 'hex',
            '—à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è': 'hex',
            '—à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω—ã–π': 'hex',
            '–∏–º–±—É—Å': 'hex',
            'hex': '—à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫',
            '—Ç–æ—Ä–∫—Å': 'torx',
            'torx': '—Ç–æ—Ä–∫—Å',
            '–∑–≤–µ–∑–¥–æ—á–∫–∞': 'torx',
            '–∑–≤–µ–∑–¥–æ–æ–±—Ä–∞–∑–Ω–∞—è': 'torx',

            # –ö–õ–Æ–ß–ò
            '–∫–ª—é—á': '–≥–∞–µ—á–Ω—ã–π',
            '–≥–∞–µ—á–Ω—ã–π': '–∫–ª—é—á',
            '—Ä–æ–∂–∫–æ–≤—ã–π': '–æ—Ç–∫—Ä—ã—Ç—ã–π',
            '–æ—Ç–∫—Ä—ã—Ç—ã–π': '—Ä–æ–∂–∫–æ–≤—ã–π',
            '–Ω–∞–∫–∏–¥–Ω–æ–π': '–∫–æ–ª—å—Ü–µ–≤–æ–π',
            '–∫–æ–ª—å—Ü–µ–≤–æ–π': '–Ω–∞–∫–∏–¥–Ω–æ–π',
            '—Ä–æ–∂–∫–æ–≤–æ-–Ω–∞–∫–∏–¥–Ω–æ–π': '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π',
            '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π': '—Ä–æ–∂–∫–æ–≤–æ-–Ω–∞–∫–∏–¥–Ω–æ–π',
            '—Ä–∞–∑–≤–æ–¥–Ω–æ–π': 'adjustable',
            'adjustable': '—Ä–∞–∑–≤–æ–¥–Ω–æ–π',

            # –ì–û–õ–û–í–ö–ò –ò –ù–ê–°–ê–î–ö–ò
            '–≥–æ–ª–æ–≤–∫–∞': '–Ω–∞—Å–∞–¥–∫–∞',
            '–Ω–∞—Å–∞–¥–∫–∞': '–≥–æ–ª–æ–≤–∫–∞',
            '—Ç–æ—Ä—Ü–µ–≤–∞—è': '–≥–æ–ª–æ–≤–æ—á–Ω–∞—è',
            '–≥–æ–ª–æ–≤–æ—á–Ω–∞—è': '—Ç–æ—Ä—Ü–µ–≤–∞—è',
            '—Ç–æ—Ä—Ü–æ–≤–∞—è': '–≥–æ–ª–æ–≤–æ—á–Ω–∞—è',
            'socket': '–≥–æ–ª–æ–≤–∫–∞',

            # –£–î–õ–ò–ù–ò–¢–ï–õ–ò
            '—É–¥–ª–∏–Ω–∏—Ç–µ–ª—å': '–∫–∞—Ä–¥–∞–Ω–Ω—ã–π',
            '–∫–∞—Ä–¥–∞–Ω–Ω—ã–π': '—É–¥–ª–∏–Ω–∏—Ç–µ–ª—å',
            '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫': '–∞–¥–∞–ø—Ç–µ—Ä',
            '–∞–¥–∞–ø—Ç–µ—Ä': '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫',
            'extension': '—É–¥–ª–∏–Ω–∏—Ç–µ–ª—å',

            # –°–¢–†–£–ë–¶–ò–ù–´
            '—Å—Ç—Ä—É–±—Ü–∏–Ω–∞': '–∑–∞–∂–∏–º',
            '–∑–∞–∂–∏–º': '—Å—Ç—Ä—É–±—Ü–∏–Ω–∞',
            '—Ç–∏—Å–∫–∏': '–∑–∞–∂–∏–º',
            'clamp': '—Å—Ç—Ä—É–±—Ü–∏–Ω–∞',
            'g-–æ–±—Ä–∞–∑–Ω–∞—è': 'g-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞',
            'f-–æ–±—Ä–∞–∑–Ω–∞—è': 'f-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞',

            # –ü–ê–°–°–ê–¢–ò–ñ–ò
            '–ø–ª–æ—Å–∫–æ–≥—É–±—Ü—ã': '–ø–∞—Å—Å–∞—Ç–∏–∂–∏',
            '–ø–∞—Å—Å–∞—Ç–∏–∂–∏': '–ø–ª–æ—Å–∫–æ–≥—É–±—Ü—ã',
            '–∫—É—Å–∞—á–∫–∏': '–±–æ–∫–æ—Ä–µ–∑—ã',
            '–±–æ–∫–æ—Ä–µ–∑—ã': '–∫—É—Å–∞—á–∫–∏',
            '–∫—Ä—É–≥–ª–æ–≥—É–±—Ü—ã': '–ø–ª–æ—Å–∫–æ–≥—É–±—Ü—ã',
            '–¥–ª–∏–Ω–Ω–æ–≥—É–±—Ü—ã': '–ø–ª–æ—Å–∫–æ–≥—É–±—Ü—ã',

            # –ú–û–õ–û–¢–ö–ò
            '–º–æ–ª–æ—Ç–æ–∫': '–∫—É–≤–∞–ª–¥–∞',
            '–∫—É–≤–∞–ª–¥–∞': '–º–æ–ª–æ—Ç–æ–∫',
            '–∫–∏—è–Ω–∫–∞': '–º–æ–ª–æ—Ç–æ–∫',
            'hammer': '–º–æ–ª–æ—Ç–æ–∫',

            # –ü–ù–ï–í–ú–ê–¢–ò–ß–ï–°–ö–ò–ï
            '–ø–Ω–µ–≤–º–æ—Ç—Ä–µ—â–æ—Ç–∫–∞': '–ø–Ω–µ–≤–º–æ—Ç—Ä–µ—â–µ—Ç–∫–∞',
            '–ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∏–π': '–ø–Ω–µ–≤–º–æ',
            '–ø–Ω–µ–≤–º–æ': '–ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∏–π',
            '—Ç—Ä–µ—â–æ—Ç–∫–∞': '—Ç—Ä–µ—â–µ—Ç–∫–∞',
            '—Ç—Ä–µ—â–µ—Ç–∫–∞': '—Ç—Ä–µ—â–æ—Ç–∫–∞',
            'ratchet': '—Ç—Ä–µ—â–æ—Ç–∫–∞',

            # –ú–ê–¢–ï–†–ò–ê–õ–´
            '—Ö—Ä–æ–º–≤–∞–Ω–∞–¥–∏–µ–≤–∞—è': 'crv',
            '—Ö—Ä–æ–º-–≤–∞–Ω–∞–¥–∏–π': 'crv',
            'chrome-vanadium': 'crv',
            'cr-v': 'crv',
            'crv': '—Ö—Ä–æ–º-–≤–∞–Ω–∞–¥–∏–π',
            'crmo': '—Ö—Ä–æ–º-–º–æ–ª–∏–±–¥–µ–Ω',
            'cr-mo': '—Ö—Ä–æ–º-–º–æ–ª–∏–±–¥–µ–Ω',
            'chrome-molybdenum': 'crmo',

            # –ü–û–ö–†–´–¢–ò–Ø
            '—Ö—Ä–æ–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è': 'chrome',
            'chrome': '—Ö—Ä–æ–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è',
            '–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è': 'polished',
            'polished': '–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è',
            '–º–∞—Ç–æ–≤–∞—è': 'matt',
            'matt': '–º–∞—Ç–æ–≤–∞—è',

            # –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –û–ë–û–ó–ù–ê–ß–ï–ù–ò–Ø
            'vde': '–∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π',
            '–∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π': 'vde',
            'anti-slip': '–ø—Ä–æ—Ç–∏–≤–æ—Å–∫–æ–ª—å–∑—è—â–∏–π',
            '–ø—Ä–æ—Ç–∏–≤–æ—Å–∫–æ–ª—å–∑—è—â–∏–π': 'anti-slip',
            'grip': '—Ä—É–∫–æ—è—Ç–∫–∞',
            '—Ä—É–∫–æ—è—Ç–∫–∞': 'grip',
            'ergonic': '—ç—Ä–≥–æ–Ω–æ–º–∏—á–Ω—ã–π',
            '—ç—Ä–≥–æ–Ω–æ–º–∏—á–Ω—ã–π': 'ergonic',

            # –†–ê–ó–ú–ï–†–´ (–¥—é–π–º—ã –≤ –º–º)
            '1/4': '6.35',
            '5/16': '7.94',
            '3/8': '9.53',
            '7/16': '11.11',
            '1/2': '12.70',
            '9/16': '14.29',
            '5/8': '15.88',
            '11/16': '17.46',
            '3/4': '19.05',
            '7/8': '22.23',

            # –°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï –ü–†–û–§–ò–õ–ò
            'spline': '—à–ª–∏—Ü–µ–≤–æ–π',
            '—à–ª–∏—Ü–µ–≤–æ–π': 'spline',
            'square': '–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π',
            '–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π': 'square',
            '–∫–≤–∞–¥—Ä–∞—Ç': 'square',

            # –≠–õ–ï–ö–¢–†–ò–ß–ï–°–ö–ò–ï
            'awg': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π-–∫–∞–ª–∏–±—Ä',
            'wire': '–ø—Ä–æ–≤–æ–¥',
            '–ø—Ä–æ–≤–æ–¥': 'wire',
            'cable': '–∫–∞–±–µ–ª—å',
            '–∫–∞–±–µ–ª—å': 'cable',

            # –ë–£–†–´ –ò –°–í–ï–†–õ–ê
            'sds-max': 'sds-–º–∞–∫—Å',
            'sds-plus': 'sds-–ø–ª—é—Å',
            'drill': '—Å–≤–µ—Ä–ª–æ',
            '—Å–≤–µ—Ä–ª–æ': 'drill',
            '–±—É—Ä': 'drill',
        }

        # –ë—Ä–µ–Ω–¥—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        self.brands = {
            'kingtony', 'king-tony', 'jtc', 'matrix', 'gross', 'stayer',
            'fit', 'kraftool', '–∑—É–±—Ä', '–≤–∏—Ö—Ä—å', '–ø–∞—Ç—Ä–∏–æ—Ç', '–∫–∞–ª–∏–±—Ä',
            '–∫—Ä–∞—Ç–æ–Ω', '–∏–Ω—Ç–µ—Ä—Å–∫–æ–ª', 'skrab', 'rockforce', 'forsage',
            'berger', 'hans', 'stanley', 'bosch', 'makita', 'sparta'
        }

    def normalize_technical_designations(self, text):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π"""
        text = text.lower()

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∫–æ–¥–æ–≤
        text = re.sub(r'ph\s*(\d+)', r'phillips \1', text)  # PH1, PH2 ‚Üí phillips
        text = re.sub(r'sl\s*(\d+(?:[.,]\d+)?)', r'slotted \1', text)  # SL3, SL4 ‚Üí slotted
        text = re.sub(r't(\d+)', r'torx \1', text)  # T10, T20 ‚Üí torx
        text = re.sub(r'h(\d+)', r'hex \1', text)  # H3, H4 ‚Üí hex
        text = re.sub(r'pz\s*(\d+)', r'pozidriv \1', text)  # PZ1, PZ2 ‚Üí pozidriv
        text = re.sub(r'g-?\s*(\d+)', r'g-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞ \1', text)  # G-75 ‚Üí g-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞
        text = re.sub(r'f-?\s*(\d+)', r'f-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞ \1', text)  # F-300 ‚Üí f-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞

        return text

    def analyze_similarity_batch(self, masters, nomenclatures):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è–º–∏"""
        print("üöÄ –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø SuperEnhancedTextAnalyzer!")
        similarities = []

        for i, (master, nomenclature) in enumerate(zip(masters, nomenclatures)):
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è
            master_norm = self.normalize_technical_designations(master)
            nomenclature_norm = self.normalize_technical_designations(nomenclature)

            # –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            semantic_score = self._enhanced_semantic_similarity(master_norm, nomenclature_norm)
            size_score = self._enhanced_size_similarity(master, nomenclature)

            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (90% —Å–µ–º–∞–Ω—Ç–∏–∫–∞ + 10% —Ä–∞–∑–º–µ—Ä)
            total_score = semantic_score * 0.9 + size_score * 0.1
            similarities.append(min(1.0, max(0.0, total_score)))

            if i % 1000 == 0 and i > 0:
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(masters)} –ø–∞—Ä")

        return similarities

    def _enhanced_semantic_similarity(self, master, nomenclature):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ"""
        master_terms = self._extract_enhanced_terms(master)
        nomenclature_terms = self._extract_enhanced_terms(nomenclature)

        if not master_terms or not nomenclature_terms:
            return 0.1

        # –ë–∞–∑–æ–≤–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        intersection = len(master_terms & nomenclature_terms)
        union = len(master_terms | nomenclature_terms)
        base_similarity = intersection / union if union > 0 else 0.0

        # –ë–æ–Ω—É—Å –∑–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        functional_bonus = self._calculate_functional_bonus(master_terms, nomenclature_terms)

        return min(1.0, base_similarity + functional_bonus)

    def _calculate_functional_bonus(self, master_terms, nomenclature_terms):
        """–ë–æ–Ω—É—Å –∑–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ"""
        bonus = 0.0

        # –ì—Ä—É–ø–ø—ã —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        functional_groups = [
            {'phillips', '–∫—Ä–µ—Å—Ç–æ–æ–±—Ä–∞–∑–Ω–∞—è', 'ph'},
            {'slotted', '—à–ª–∏—Ü–µ–≤–∞—è', 'sl', '–ø—Ä—è–º–∞—è'},
            {'torx', '—Ç–æ—Ä–∫—Å', '–∑–≤–µ–∑–¥–æ—á–∫–∞'},
            {'hex', '—à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫', '–∏–º–±—É—Å'},
            {'g-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞', 'g-–æ–±—Ä–∞–∑–Ω–∞—è', '—Å—Ç—Ä—É–±—Ü–∏–Ω–∞'},
            {'f-—Å—Ç—Ä—É–±—Ü–∏–Ω–∞', 'f-–æ–±—Ä–∞–∑–Ω–∞—è', '—Å—Ç—Ä—É–±—Ü–∏–Ω–∞'},
            {'–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π', '—Ä–æ–∂–∫–æ–≤–æ-–Ω–∞–∫–∏–¥–Ω–æ–π'},
            {'–æ—Ç–≤–µ—Ä—Ç–∫–∞', '–æ—Ç–≤–µ—Ä—Ç–æ—á–Ω–∞—è', '–±–∏—Ç–∞'},
            {'–º–æ–ª–æ—Ç–æ–∫', '–∫—É–≤–∞–ª–¥–∞', '–∫–∏—è–Ω–∫–∞'},
            {'–ø–ª–æ—Å–∫–æ–≥—É–±—Ü—ã', '–ø–∞—Å—Å–∞—Ç–∏–∂–∏', '–∫—É—Å–∞—á–∫–∏'}
        ]

        for group in functional_groups:
            master_has = bool(master_terms & group)
            nomenclature_has = bool(nomenclature_terms & group)

            if master_has and nomenclature_has:
                bonus += 0.5  # –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –±–æ–Ω—É—Å –∑–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ

        return bonus

    def _extract_enhanced_terms(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
        for old, new in self.technical_synonyms.items():
            text = text.replace(old, new)

        # –£–±–∏—Ä–∞–µ–º –±—Ä–µ–Ω–¥—ã
        for brand in self.brands:
            text = re.sub(r'\b' + re.escape(brand) + r'\b', '', text)

        # –£–±–∏—Ä–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã –∏ –∫–æ–¥—ã
        text = re.sub(r'\b\d+[a-z]+-?\d+[a-z]*\b', '', text)  # 8PK-301F
        text = re.sub(r'\b[a-z]+-?\d+[a-z]*\b', '', text)  # CP-371V

        # –û—á–∏—Å—Ç–∫–∞
        text = re.sub(r'[^a-z–∞-—è—ë0-9\s-]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        terms = set()
        words = text.split()

        for word in words:
            if len(word) > 2 and word not in {'–¥–ª—è', '–∏–ª–∏', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–∫–∞–∫', '—á—Ç–æ', '–º–º', '—Å–º'}:
                terms.add(word)

        return terms

    def _enhanced_size_similarity(self, master, nomenclature):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤"""
        master_sizes = self._extract_sizes(master)
        nomenclature_sizes = self._extract_sizes(nomenclature)

        if not master_sizes or not nomenclature_sizes:
            return 0.5  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
        for m_size in master_sizes:
            for n_size in nomenclature_sizes:
                if abs(m_size - n_size) / max(m_size, n_size) <= 0.1:  # 10% –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å
                    return 1.0

        return 0.0

    def _extract_sizes(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤"""
        sizes = []

        # –†–∞–∑–º–µ—Ä—ã –≤ –º–º
        mm_matches = re.findall(r'(\d+(?:[.,]\d+)?)\s*–º–º', text.lower())
        for match in mm_matches:
            try:
                sizes.append(float(match.replace(',', '.')))
            except ValueError:
                continue

        # –î—é–π–º–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        inch_patterns = [r'(\d+/\d+)']
        for pattern in inch_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    parts = match.split('/')
                    if len(parts) == 2:
                        inch_size = float(parts[0]) / float(parts[1])
                        sizes.append(inch_size * 25.4)  # –≤ –º–º
                except (ValueError, ZeroDivisionError):
                    continue

        # –ü—Ä–æ—Å—Ç—ã–µ —á–∏—Å–ª–∞ (—Ä–∞–∑–º–µ—Ä—ã)
        numbers = re.findall(r'\b(\d+)\b', text)
        for num in numbers:
            try:
                n = float(num)
                if 4 <= n <= 50:  # —Ä–∞–∑—É–º–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω —Ä–∞–∑–º–µ—Ä–æ–≤
                    sizes.append(n)
            except ValueError:
                continue

        return sizes


class FileReader:
    def read_data(self, file_path):
        print(f"–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {file_path}")
        if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
            df = pd.read_excel(file_path, sheet_name=0, engine='openpyxl')
        else:
            df = pd.read_csv(file_path, encoding='utf-8')

        if len(df.columns) >= 2:
            df.columns = ['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è', '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'] + list(df.columns[2:])

        df = df.dropna(subset=['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è', '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'])
        df['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è'] = df['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è'].astype(str)
        df['–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'] = df['–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'].astype(str)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        return df


class FileWriter:
    def save_anomalies(self, df, file_path):
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        df_with_meta = df.copy()
        df_with_meta['detection_timestamp'] = pd.Timestamp.now()
        df_with_meta.to_csv(file_path, index=False, encoding='utf-8')
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {file_path}")
        return file_path


def main():
    logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

    # –ü–æ–∏—Å–∫ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    possible_files = [
        'data/input.xlsx',
        'data/master_nomenclature.xlsx',
        '–ú–∞—Å—Ç–µ—Ä –ø–æ–∑–∏—Ü–∏—è - –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ ‚Äî –∫–æ–ø–∏—è.xlsx',
        '../data/input.xlsx'
    ]

    input_file = None
    for path in possible_files:
        if os.path.exists(path):
            input_file = path
            break

    if not input_file:
        print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è - –ò–°–ü–û–õ–¨–ó–£–ï–ú –ü–†–ê–í–ò–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–†!
    reader = FileReader()
    writer = FileWriter()
    analyzer = SuperEnhancedTextAnalyzer()  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û!

    df = reader.read_data(input_file)
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")

    print("üîç –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
    similarities = analyzer.analyze_similarity_batch(
        df['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è'].tolist(),
        df['–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'].tolist()
    )

    df['similarity_score'] = similarities

    # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ (–Ω–∏–∂–Ω–∏–µ 3%)
    threshold = np.percentile(similarities, 3)
    print(f"üéØ –í—ã—á–∏—Å–ª–µ–Ω –ø–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–π: {threshold:.3f}")

    df['is_anomaly'] = df['similarity_score'] < threshold
    anomalies = df[df['is_anomaly']].copy()
    anomalies = anomalies.sort_values('similarity_score')

    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π –∏–∑ {len(df)} –∑–∞–ø–∏—Å–µ–π ({len(anomalies) / len(df) * 100:.1f}%)")

    if len(anomalies) > 0:
        writer.save_anomalies(anomalies, 'data/super_enhanced_anomalies.csv')

        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–π: {anomalies['similarity_score'].mean():.3f}")

        print("\nüîç –¢–û–ü-5:")
        for i, (_, row) in enumerate(anomalies.head(5).iterrows(), 1):
            print(f"{i}. –°—Ö–æ–∂–µ—Å—Ç—å: {row['similarity_score']:.3f}")
            print(f"   –ú–∞—Å—Ç–µ—Ä: {row['–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è'][:50]}...")
            print(f"   –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞: {row['–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'][:50]}...")
    else:
        print("‚úÖ –ê–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")


if __name__ == "__main__":
    main()



#TODO –ø–æ—á–∏—Å—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç
#TODO –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —Å–∏–Ω–æ–Ω–∏–º—ã
#TODO –¥–æ–±–∞–≤–∏—Ç—å —Å–∏–Ω–æ–Ω–∏–º—ã —Å —Å–∞–π—Ç–∞
#TODO –ö–∏–Ω—É—Ç—å –Ω–∞ —Å–≤–µ—Ä–∫—É —Ñ–∞–π–ª –¥–ª—è 5 —Ä–∞–∑–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–∫( –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –≤ —Ä—É—á–Ω—É—é –≤—ã—é—Ä–∞—Ç—å –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏, GPT-5 –∏ 5 –¥—É–º–∞—é—â–∞—è, Claude tinkin, cloud sonnet, gemini 2.5, grog,o3)
# –†–∞–∑–±–∏—Ç—å —Ñ–∞–π–ª –Ω–∞ 5 —á–∞—Å—Ç–µ–π , –≤–æ—Ç –ø—Ä–æ–º–ø—Ç
# # –ó–ê–î–ê–ß–ê: –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö "–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è ‚Üí –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞"
#
# ## –ö–æ–Ω—Ç–µ–∫—Å—Ç
# –¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. –ü–µ—Ä–µ–¥ —Ç–æ–±–æ–π —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–º–∏:
# - **–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è**: –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ
# - **–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞**: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–æ–≤–∞—Ä –≤ —Å–∏—Å—Ç–µ–º–µ –∑–∞–∫—É–ø–æ–∫
#
# ## –¶–µ–ª—å
# –ù–∞–π—Ç–∏ **–∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã**, –≥–¥–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏–∏.
#
# ## –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π
# üö® **–ê–ù–û–ú–ê–õ–ò–Ø** - —ç—Ç–æ –∫–æ–≥–¥–∞:
# - –†–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–∫–ª—é—á ‚Üí –æ—Ç–≤–µ—Ä—Ç–∫–∞)
# - –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã (10–º–º ‚Üí 1/2")
# - –†–∞–∑–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ (–ø–Ω–µ–≤–º–æ–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç ‚Üí —Ä—É—á–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç)
# - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ (–º–æ–ª–æ—Ç–æ–∫ ‚Üí —à–ª–∞–Ω–≥)
#
# ‚úÖ **–ù–ï –∞–Ω–æ–º–∞–ª–∏—è**:
# - –°–∏–Ω–æ–Ω–∏–º—ã ("—Ä–æ–∂–∫–æ–≤–æ-–Ω–∞–∫–∏–¥–Ω–æ–π" = "–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π")
# - –†–∞–∑–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
# - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è (PH = Phillips, SL = Slotted)
# - –†–∞–∑–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
#
# ## –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
# –î–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∞–Ω–æ–º–∞–ª–∏–∏ —É–∫–∞–∂–∏:
# 1. **–ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏**
# 2. **–ú–∞—Å—Ç–µ—Ä-–ø–æ–∑–∏—Ü–∏—è**: [—Ç–µ–∫—Å—Ç]
# 3. **–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞**: [—Ç–µ–∫—Å—Ç]
# 4. **–¢–∏–ø –∞–Ω–æ–º–∞–ª–∏–∏**: [–∫–∞—Ç–µ–≥–æ—Ä–∏—è/—Ä–∞–∑–º–µ—Ä/–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ/—Å–µ–º–∞–Ω—Ç–∏–∫–∞]
# 5. **–û–±—ä—è—Å–Ω–µ–Ω–∏–µ**: –ø–æ—á–µ–º—É —ç—Ç–æ –∞–Ω–æ–º–∞–ª–∏—è –≤ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
#
# ## –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
# - –ù–∞–π–¥–∏ –≤—Å–µ –∞–Ω–æ–º–∞–ª–∏–∏ –∏ –∑–∞–ø–∏—à–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª, –ø–æ–¥–ø–∏—à–∏ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏
# - –§–æ–∫—É—Å –Ω–∞ –û–ß–ï–í–ò–î–ù–´–• –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è—Ö
# - –ù–ï —Å—á–∏—Ç–∞–π —Å–∏–Ω–æ–Ω–∏–º—ã –∞–Ω–æ–º–∞–ª–∏—è–º–∏
#
# –ù–∞—á–∏–Ω–∞–π –∞–Ω–∞–ª–∏–∑!
